{"title":"Why I'm Building an AI Engineer Curriculum in Public","markdown":{"yaml":{"title":"Why I'm Building an AI Engineer Curriculum in Public","description":"Kicking off the blog with intent, scope, and how I’ll share progress.","date":"2025-10-21"},"headingText":"I want to retrain to make AI systems","containsRefs":false,"markdown":"\n\n\nWhy a change in career? I've been finding fullstack engineering un-impactful and un-fulfilling. Rendering out data on a page; designing that page to pixel perfection, and getting millions of clicks on buttons I have created doesn't feel awesome to me.\n\nI'm so glad I went down this route and tried it out... however when I tell people what they should do with their lives, I tell them to study AI and get involved. \n\nIt is the next technological revolution and I want to be part of it. I like how it's the closest thing to understand the human brain and trying to emulate it. I like how we become gods in a way of our own simulation. - It's becoming clearer that we are within a simulation, so I want to be a part of the people able to bend the matrix and understand it.\n\nAI isn't only interesting for making lots of money. It could do so much for us. [Neuralink](https://neuralink.com/) comes to mind. That's directly some of the most incredible impactful outcomes I've seen in my life.\n\nIn another sense I want to get to see AGI. To understand the human mind, truly. I find human intelligence fascinating.\n\n\n### My Dream job \n\n- Title: AGI Engineer\n- Team: The Artificial General Intelligence (AGI) team \n- Working for a massive well known company like OpenAI, Meta, Amazon...\n- prototype new technology\n- Work on creating systems better than the human brain\n- Proven track record of designing, building, and shipping real-time ML products\n- Strong foundation in signal processing, algorithms, and software engineering principles\n\n> I need to find the most fascinating stage of training Neural Networks to me, then I'll find the right specialisation.\n\n### Sample Projects must be in portfolio\n\nOptimizing the throughput of novel attention mechanisms\nComparing compute efficiency of different Transformer variants\nPreparing large-scale datasets for efficient model consumption\nScaling distributed training jobs to thousands of GPUs\nDesigning fault tolerance strategies for our training infrastructure\nCreating interactive visualizations of model internals, such as attention patterns\n\n### Must-Haves from listings\n\n- Computer Science Degree or equivalent\n- Possess strong programming skills in Python\n- Expertise in Python and experience with deep learning frameworks (PyTorch preferred)\n- Implementing LLM finetuning algorithms, such as RLHF\n- Experience with open-source ML toolkits and frameworks (eg. PyTorch, TensorFlow, etc)\n- Have experience with training, evaluating, or monitoring large language models\n- Language modeling with transformers\n- Large-scale ETL\nWork on high-performance, large-scale ML systems\nFamiliarity with GPUs, Kubernetes, and OS internals\nExperience with language modeling using transformer architectures\nKnowledge of reinforcement learning techniques\nBackground in large-scale ETL processes\nAre eager to learn more about machine learning research\nAre working to align state of the art models with human values and preferences, understand and interpret deep neural networks, or develop new models to support these areas of research\nView research and engineering as two sides of the same coin, and seek to understand all aspects of our research program as well as possible, to maximize the impact of your insights\nHave ambitious goals for AI safety and general progress in the next few years, and you’re working to create the best outcomes over the long-term.\n- GPUs, Kubernetes, Pytorch, or OS internals\n- Independently lead small research projects\n- Conduct research and implement solutions in areas such as model architecture, algorithms, data processing, and optimizer development\n- Design, run, and analyze scientific experiments to advance our understanding of large language models\n- Optimize and scale our training infrastructure to improve efficiency and reliability\n\n- Published work on hallucination prevention, factual grounding, or knowledge integration in language models\n- Experience with fact-grounding techniques\n- Background in developing confidence estimation or calibration methods for ML models\n- A track record of creating and maintaining factual knowledge bases\n- Familiarity with RLHF specifically applied to improving model truthfulness\n- Worked with crowd-sourcing platforms and human feedback collection systems\n- Experience developing evaluations of model accuracy or hallucinations\n- Have industry experience with language model finetuning and classifier training\n- Show proficiency in experimental design and statistical analysis for measuring improvements in calibration and accuracy\n- Care about AI safety and the accuracy and honesty of both current and future AI systems\n- Have experience in data science or the creation and curation of datasets for finetuning LLMs\n- An understanding of various metrics of uncertainty, calibration, and truthfulness in model outputs\n- demonstrable track record of success in delivering new features and products\n- Creating reliable, scalable, and high performance AI products\n- Knowledge of design or architecture (design patterns, reliability and scaling) of new and existing systems experience\n- development of techniques to minimize hallucinations and enhance truthfulness in language models\n- Design and implement novel data curation pipelines to identify, verify, and filter training data for accuracy given the model’s knowledge\n- Develop specialized classifiers to detect potential hallucinations or miscalibrated claims made by the mode\n- Create and maintain comprehensive honesty benchmarks and evaluation frameworks\n- Implement techniques to ground model outputs in verified information, such as search and retrieval-augmented generation (RAG) systems\n- Design and deploy human feedback collection specifically for identifying and correcting miscalibrated responses\n- Design and implement prompting pipelines to generate data that improves model accuracy and honesty\n- Develop and test novel RL environments that reward truthful outputs and penalize fabricated claims\n- Create tools to help human evaluators efficiently assess model outputs for accuracy\n- Design, develop, and maintain tokenization systems used across Pretraining and Finetuning workflows\n- Optimize encoding techniques to improve model training efficiency and performance\n- Collaborate closely with research teams to understand their evolving needs around data representation\n- Build infrastructure that enables researchers to experiment with novel tokenization approaches\n- Implement systems for monitoring and debugging tokenization-related issues in the model training pipeline\n- Create robust testing frameworks to validate tokenization systems across diverse languages and data types\n- Identify and address bottlenecks in data processing pipelines related to tokenization\n- Document systems thoroughly and communicate technical decisions clearly to stakeholders across teams \n- Working with machine learning data processing pipelines\n- Building or optimizing data encodings for ML applications\n- Implementing or working with BPE, WordPiece, or other tokenization algorithms\n- Performance optimization of ML data processing systems\n- Multi-language tokenization challenges and solutions\n- Research environments where engineering directly enables scientific progress\n- Distributed systems and parallel computing for ML workflows\n- Large language models or other transformer-based architectures (not required) \n- Profiling our reinforcement learning pipeline to find opportunities for improvement\nBuilding a system that regularly launches training jobs in a test environment so that we can quickly detect problems in the training pipeline\nMaking changes to our finetuning systems so they work on new model architectures\nBuilding instrumentation to detect and eliminate Python GIL contention in our training code\nDiagnosing why training runs have started slowing down after some number of steps, and fixing it\nImplementing a stable, fast version of a new training algorithm proposed by a researcher\n\nDevelop next-generation evaluation frameworks - Move beyond traditional benchmarks to create evaluations that capture real-world utility\n\nCreate automated quality assessment pipelines - Build custom classifiers to continuously monitor RL transcripts for complex issues\n\nBuild comprehensive training observability systems - Design and implement monitoring infrastructure to keep an eye on how model behaviors evolve throughout training.\n\nBridge research and production - Partner with research teams to translate cutting-edge evaluation techniques into production-ready systems, and work with engineering teams to ensure our monitoring infrastructure scales with increasingly complex training workflows.\n\n\n\n##### Ideal working environment\n- Work from home, flexible working hours\n- Learning days and study days\n- Open sharing environment \n\n\n\n\n#### Listings\n\n- [Research Engineer, Pre-training](https://job-boards.greenhouse.io/anthropic/jobs/4681526008)\n- [Anthropic - Machine Learning Systems Engineer, Research Tools](https://job-boards.greenhouse.io/anthropic/jobs/4952079008)\n- [Anthrophic - [Expression of Interest] Research Scientist/Engineer, Honesty](https://job-boards.greenhouse.io/anthropic/jobs/4532887008)\n- [Anthropic - Machine Learning Systems Engineer, RL Engineering](https://job-boards.greenhouse.io/anthropic/jobs/4952051008)\n- [Amazon - Software Development Engineer (ML), AGI Customization](https://www.amazon.jobs/en-gb/jobs/3102530/software-development-engineer-ml-agi-customization)\n- [Amazon - Sr. Research Engineer, Machine Learning, AGI Foundations](https://www.amazon.jobs/en-gb/jobs/3113050/sr-research-engineer-machine-learning-agi-foundations)\n\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/FASMejN_5gs?si=ubOyj1Zwey6xvBgo\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>","srcMarkdownNoYaml":"\n\n### I want to retrain to make AI systems\n\nWhy a change in career? I've been finding fullstack engineering un-impactful and un-fulfilling. Rendering out data on a page; designing that page to pixel perfection, and getting millions of clicks on buttons I have created doesn't feel awesome to me.\n\nI'm so glad I went down this route and tried it out... however when I tell people what they should do with their lives, I tell them to study AI and get involved. \n\nIt is the next technological revolution and I want to be part of it. I like how it's the closest thing to understand the human brain and trying to emulate it. I like how we become gods in a way of our own simulation. - It's becoming clearer that we are within a simulation, so I want to be a part of the people able to bend the matrix and understand it.\n\nAI isn't only interesting for making lots of money. It could do so much for us. [Neuralink](https://neuralink.com/) comes to mind. That's directly some of the most incredible impactful outcomes I've seen in my life.\n\nIn another sense I want to get to see AGI. To understand the human mind, truly. I find human intelligence fascinating.\n\n\n### My Dream job \n\n- Title: AGI Engineer\n- Team: The Artificial General Intelligence (AGI) team \n- Working for a massive well known company like OpenAI, Meta, Amazon...\n- prototype new technology\n- Work on creating systems better than the human brain\n- Proven track record of designing, building, and shipping real-time ML products\n- Strong foundation in signal processing, algorithms, and software engineering principles\n\n> I need to find the most fascinating stage of training Neural Networks to me, then I'll find the right specialisation.\n\n### Sample Projects must be in portfolio\n\nOptimizing the throughput of novel attention mechanisms\nComparing compute efficiency of different Transformer variants\nPreparing large-scale datasets for efficient model consumption\nScaling distributed training jobs to thousands of GPUs\nDesigning fault tolerance strategies for our training infrastructure\nCreating interactive visualizations of model internals, such as attention patterns\n\n### Must-Haves from listings\n\n- Computer Science Degree or equivalent\n- Possess strong programming skills in Python\n- Expertise in Python and experience with deep learning frameworks (PyTorch preferred)\n- Implementing LLM finetuning algorithms, such as RLHF\n- Experience with open-source ML toolkits and frameworks (eg. PyTorch, TensorFlow, etc)\n- Have experience with training, evaluating, or monitoring large language models\n- Language modeling with transformers\n- Large-scale ETL\nWork on high-performance, large-scale ML systems\nFamiliarity with GPUs, Kubernetes, and OS internals\nExperience with language modeling using transformer architectures\nKnowledge of reinforcement learning techniques\nBackground in large-scale ETL processes\nAre eager to learn more about machine learning research\nAre working to align state of the art models with human values and preferences, understand and interpret deep neural networks, or develop new models to support these areas of research\nView research and engineering as two sides of the same coin, and seek to understand all aspects of our research program as well as possible, to maximize the impact of your insights\nHave ambitious goals for AI safety and general progress in the next few years, and you’re working to create the best outcomes over the long-term.\n- GPUs, Kubernetes, Pytorch, or OS internals\n- Independently lead small research projects\n- Conduct research and implement solutions in areas such as model architecture, algorithms, data processing, and optimizer development\n- Design, run, and analyze scientific experiments to advance our understanding of large language models\n- Optimize and scale our training infrastructure to improve efficiency and reliability\n\n- Published work on hallucination prevention, factual grounding, or knowledge integration in language models\n- Experience with fact-grounding techniques\n- Background in developing confidence estimation or calibration methods for ML models\n- A track record of creating and maintaining factual knowledge bases\n- Familiarity with RLHF specifically applied to improving model truthfulness\n- Worked with crowd-sourcing platforms and human feedback collection systems\n- Experience developing evaluations of model accuracy or hallucinations\n- Have industry experience with language model finetuning and classifier training\n- Show proficiency in experimental design and statistical analysis for measuring improvements in calibration and accuracy\n- Care about AI safety and the accuracy and honesty of both current and future AI systems\n- Have experience in data science or the creation and curation of datasets for finetuning LLMs\n- An understanding of various metrics of uncertainty, calibration, and truthfulness in model outputs\n- demonstrable track record of success in delivering new features and products\n- Creating reliable, scalable, and high performance AI products\n- Knowledge of design or architecture (design patterns, reliability and scaling) of new and existing systems experience\n- development of techniques to minimize hallucinations and enhance truthfulness in language models\n- Design and implement novel data curation pipelines to identify, verify, and filter training data for accuracy given the model’s knowledge\n- Develop specialized classifiers to detect potential hallucinations or miscalibrated claims made by the mode\n- Create and maintain comprehensive honesty benchmarks and evaluation frameworks\n- Implement techniques to ground model outputs in verified information, such as search and retrieval-augmented generation (RAG) systems\n- Design and deploy human feedback collection specifically for identifying and correcting miscalibrated responses\n- Design and implement prompting pipelines to generate data that improves model accuracy and honesty\n- Develop and test novel RL environments that reward truthful outputs and penalize fabricated claims\n- Create tools to help human evaluators efficiently assess model outputs for accuracy\n- Design, develop, and maintain tokenization systems used across Pretraining and Finetuning workflows\n- Optimize encoding techniques to improve model training efficiency and performance\n- Collaborate closely with research teams to understand their evolving needs around data representation\n- Build infrastructure that enables researchers to experiment with novel tokenization approaches\n- Implement systems for monitoring and debugging tokenization-related issues in the model training pipeline\n- Create robust testing frameworks to validate tokenization systems across diverse languages and data types\n- Identify and address bottlenecks in data processing pipelines related to tokenization\n- Document systems thoroughly and communicate technical decisions clearly to stakeholders across teams \n- Working with machine learning data processing pipelines\n- Building or optimizing data encodings for ML applications\n- Implementing or working with BPE, WordPiece, or other tokenization algorithms\n- Performance optimization of ML data processing systems\n- Multi-language tokenization challenges and solutions\n- Research environments where engineering directly enables scientific progress\n- Distributed systems and parallel computing for ML workflows\n- Large language models or other transformer-based architectures (not required) \n- Profiling our reinforcement learning pipeline to find opportunities for improvement\nBuilding a system that regularly launches training jobs in a test environment so that we can quickly detect problems in the training pipeline\nMaking changes to our finetuning systems so they work on new model architectures\nBuilding instrumentation to detect and eliminate Python GIL contention in our training code\nDiagnosing why training runs have started slowing down after some number of steps, and fixing it\nImplementing a stable, fast version of a new training algorithm proposed by a researcher\n\nDevelop next-generation evaluation frameworks - Move beyond traditional benchmarks to create evaluations that capture real-world utility\n\nCreate automated quality assessment pipelines - Build custom classifiers to continuously monitor RL transcripts for complex issues\n\nBuild comprehensive training observability systems - Design and implement monitoring infrastructure to keep an eye on how model behaviors evolve throughout training.\n\nBridge research and production - Partner with research teams to translate cutting-edge evaluation techniques into production-ready systems, and work with engineering teams to ensure our monitoring infrastructure scales with increasingly complex training workflows.\n\n\n\n##### Ideal working environment\n- Work from home, flexible working hours\n- Learning days and study days\n- Open sharing environment \n\n\n\n\n#### Listings\n\n- [Research Engineer, Pre-training](https://job-boards.greenhouse.io/anthropic/jobs/4681526008)\n- [Anthropic - Machine Learning Systems Engineer, Research Tools](https://job-boards.greenhouse.io/anthropic/jobs/4952079008)\n- [Anthrophic - [Expression of Interest] Research Scientist/Engineer, Honesty](https://job-boards.greenhouse.io/anthropic/jobs/4532887008)\n- [Anthropic - Machine Learning Systems Engineer, RL Engineering](https://job-boards.greenhouse.io/anthropic/jobs/4952051008)\n- [Amazon - Software Development Engineer (ML), AGI Customization](https://www.amazon.jobs/en-gb/jobs/3102530/software-development-engineer-ml-agi-customization)\n- [Amazon - Sr. Research Engineer, Machine Learning, AGI Foundations](https://www.amazon.jobs/en-gb/jobs/3113050/sr-research-engineer-machine-learning-agi-foundations)\n\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/FASMejN_5gs?si=ubOyj1Zwey6xvBgo\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"2025-10-21-first-post.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.25","execute-dir":"project","theme":["cosmo","brand"],"title":"Why I'm Building an AI Engineer Curriculum in Public","description":"Kicking off the blog with intent, scope, and how I’ll share progress.","date":"2025-10-21"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}